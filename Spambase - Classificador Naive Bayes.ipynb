{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Recuperando o que foi feito na introdução...**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "# Lendo csv\n",
    "csv_data = pd.read_csv(\"data/spambase.csv\")\n",
    "\n",
    "# Copiando os dados do csv\n",
    "data = csv_data.values.copy()\n",
    "\n",
    "# Embaralhando os dados para garantir aleatoriedade entre as amostras\n",
    "# np.random.shuffle(data)\n",
    "\n",
    "# Separando atributos de classes\n",
    "x = data[:, :-1]  # x tem apenas valores entre a primeira e penúltima coluna\n",
    "y = data[:, -1]  # y tem os valores da última coluna\n",
    "\n",
    "# 70% dos dados serão utilizados para treinamento e 30% para o teste\n",
    "# A divisão será estratificada, serão mantidas as proporções de spam e não spam em cada grupo\n",
    "x_treino, x_teste, y_treino, y_teste = train_test_split(x, y, train_size=0.7, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "# 2. Utilizando o Classificador Naive Bayes\n",
    "\n",
    "Já aprendemos na aula teórica como funciona Naive Bayes. Só relembrando: ele se chama \"Naive\" pois assume, de forma ingênua assumi, que todos os atributos são variáveis independentes, ou seja, são variáveis em que a presença ou valor não está condicionado à existência ou valor de uma outra variável.\n",
    "\n",
    "Para a nossa base de emails vamos experimentar dois tipos de classificares Naive Bayes disponível no scikit-learn, são eles:\n",
    "\n",
    "- o Bernoulli Naive Bayes, uma implementação do Naive Bayes em que o conhecimento a priori se resume a existência ou não do atributo.\n",
    "- Multinomial, uma implementação do Naive Bayes em que o conhecimento a priori se está relacionado com a frequência com que a variável ocorre na base de dados.\n",
    "\n",
    "A seguir vamos explorar melhor de cada um deles.\n",
    "\n",
    "##  2.1 Aplicando o Bernoulli Naive Bayes\n",
    "\n",
    "Nesse classificador, os atributos serão convertidos em valores binários (existe ou não existe), por padrão o threshold da binarização é 0.0, mas um novo *threshold* poderá ser definido pela variável *binarize*.\n",
    "\n",
    "Vale lembrar que os últimos 3 atributos são sempre valorados (como vimos no gráfico com a distribuição). Isso significa que, após a binarização, os valores desses atributos serão iguais a 1 sempre. Como esses atributos serão iguais para toda as amostras, a presença deles não terá importância para a classificação, logo podem ser descartados -- informação que pode ser útil está sendo jogada fora!\n",
    "\n",
    "**Para verificar a aplicação desse classificador vamos experimentar alguns cenários:**\n",
    "\n",
    "1. com todas os atributos;\n",
    "2. sem os 3 últimos atributos e com o threshold igual a 0;\n",
    "3. sem os 3 últimos atributos e com o threshold igual ao valor médio de cada um dos atributos.\n",
    "\n",
    "### 2.1.1 Com todos os atributos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bernoulli Naive Bayes\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.92      0.89      0.91       857\n",
      "        1.0       0.83      0.87      0.85       523\n",
      "\n",
      "avg / total       0.89      0.88      0.89      1380\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Classificando com o Bernoulli Naive Bayes\n",
    "cls_nb = BernoulliNB()\n",
    "# Treinamento\n",
    "cls_nb.fit(x_treino, y_treino)\n",
    "# Predição\n",
    "y_nb_pred = cls_nb.predict(x_teste)\n",
    "\n",
    "print \"Bernoulli Naive Bayes\"\n",
    "print classification_report(y_nb_pred, y_teste)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.2 Sem os 3 últimos atributos e com o threshold igual a 0:\n",
    "\n",
    "Removendo os atributos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "r_x_treino = np.delete(x_treino, [55, 56, 57], 1)  # removendo os atributos do conjunto de treino\n",
    "r_x_teste = np.delete(x_teste, [55, 56, 57], 1)  # removendo os atributos do conjunto de teste"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aplicando o classificador:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bernoulli Naive Bayes\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.92      0.89      0.91       857\n",
      "        1.0       0.83      0.87      0.85       523\n",
      "\n",
      "avg / total       0.89      0.88      0.89      1380\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Classificando com o Bernoulli Naive Bayes\n",
    "cls_nb = BernoulliNB(binarize=0.0)  # valor padrão 0.0\n",
    "# Treinamento\n",
    "cls_nb.fit(r_x_treino, y_treino)\n",
    "# Predição\n",
    "r_y_nb_pred = cls_nb.predict(r_x_teste)\n",
    "\n",
    "print \"Bernoulli Naive Bayes\"\n",
    "print classification_report(r_y_nb_pred, y_teste)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**O resultado foi o mesmo do anterior!** De fato os 3 últimos atributos não agregou qualquer valor ao classificador."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.2 Sem os 3 últimos atributos e com o threshold igual ao valor médio de cada atributo.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bernoulli Naive Bayes\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.93      0.91      0.92       858\n",
      "        1.0       0.85      0.89      0.87       522\n",
      "\n",
      "avg / total       0.90      0.90      0.90      1380\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# valor médio dos atributos:\n",
    "x_medio = np.mean(x, axis=0)\n",
    "x_medio = np.delete(x_medio, [55, 56, 57])\n",
    "\n",
    "# Classificando com o Bernoulli Naive Bayes\n",
    "cls_nb = BernoulliNB(binarize=x_medio)\n",
    "# Treinamento\n",
    "cls_nb.fit(r_x_treino, y_treino)\n",
    "# Predição\n",
    "r_y_pred_1 = cls_nb.predict(r_x_teste)\n",
    "\n",
    "print \"Bernoulli Naive Bayes\"\n",
    "print classification_report(r_y_pred_1, y_teste)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A binarização utilizando como threshold a média dos valores melhorou o desempenho do classificador."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Aplicando o Multinomial Naive Bayes\n",
    "\n",
    "Este modelo uiliza da frequência dos atributos para a classificação. O termo frequência é definido como o número de vezes que um determinado termo aparece em um documento. \n",
    "\n",
    "Só que nem todos os atributos estão em termos de frequência, como é o caso dos últimos 3 atributos. Para que o classificador funcione como desejado, é preciso fazer alguns ajustes na coleção de dados. Então, vamos fazer dois experimentos, um com todos os atributos e, novamente, removendo os últimos 3 atributos :(\n",
    "\n",
    "\n",
    "### 2.2.1 Sem qualquer alteração nos dados (não correto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multinomial Naive Bayes\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.84      0.83      0.83       848\n",
      "        1.0       0.73      0.75      0.74       532\n",
      "\n",
      "avg / total       0.80      0.80      0.80      1380\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# Classificando com o gaussian Naive Bayes\n",
    "cls_mnb = MultinomialNB()\n",
    "# Treinamento\n",
    "cls_mnb.fit(x_treino, y_treino)\n",
    "# Predição\n",
    "y_mnb_pred = cls_mnb.predict(x_teste)\n",
    "\n",
    "print \"Multinomial Naive Bayes\"\n",
    "print classification_report(y_mnb_pred, y_teste)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.2 Removendo os 3 últimos atributos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multinomial Naive Bayes\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.78      0.98      0.87       668\n",
      "        1.0       0.98      0.75      0.85       712\n",
      "\n",
      "avg / total       0.88      0.86      0.86      1380\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Classificando com o Multinomial Naive Bayes\n",
    "cls_mnb = MultinomialNB()\n",
    "# Treinamento\n",
    "cls_mnb.fit(r_x_treino, y_treino)\n",
    "# Predição\n",
    "y_mnb_pred = cls_mnb.predict(r_x_teste)\n",
    "\n",
    "print \"Multinomial Naive Bayes\"\n",
    "print classification_report(y_mnb_pred, y_teste)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.3 Como poderíamos aproveitar esses 3 últimos atributos?\n",
    "\n",
    "- [54] o comprimento médio das palavras escritas toda com letras maiúsculas.\n",
    "- [55] o comprimento da maior palavra escritas toda com letras maiúsculas.\n",
    "- [56] o total de letras em maiúsculo no email.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
